{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_link</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_country</th>\n",
       "      <th>job level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>date_posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr. Software Engineer – Distributed Graph Stor...</td>\n",
       "      <td>CrowdStrike</td>\n",
       "      <td>Nova Scotia, Canada</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/sr-software-...</td>\n",
       "      <td>12/25/23</td>\n",
       "      <td>Halifax</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Remote</td>\n",
       "      <td>#WeAreCrowdStrike and our mission is to stop b...</td>\n",
       "      <td>['Go', ' Java', ' Python', ' Git', ' Cassandra...</td>\n",
       "      <td>2024-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Java Software Engineer (Var 28)</td>\n",
       "      <td>Modis</td>\n",
       "      <td>Newark, DE</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/java-softwa...</td>\n",
       "      <td>12/25/23</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>J2EE Developer - JAVA / Full Stack\\nContract:\\...</td>\n",
       "      <td>['J2EE', ' Java', ' Struts', ' Spring', ' Spri...</td>\n",
       "      <td>2024-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Software Engineer (Backend) (Var 65)</td>\n",
       "      <td>SimplyAnalytics</td>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/senior-softw...</td>\n",
       "      <td>12/25/23</td>\n",
       "      <td>Etobicoke</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Remote</td>\n",
       "      <td>The Company\\nSimplyAnalytics is a powerful spa...</td>\n",
       "      <td>['PHP', ' Python', ' Dask', ' Dagster', ' Post...</td>\n",
       "      <td>2024-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Software Engineer (Var 46)</td>\n",
       "      <td>Changing Technologies, Inc.</td>\n",
       "      <td>Johnston, IA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-soft...</td>\n",
       "      <td>12/25/23</td>\n",
       "      <td>West Des Moines</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Job Description\\nJob Title - Senior Software E...</td>\n",
       "      <td>['Java', ' React', ' Springboot', ' AWS', ' No...</td>\n",
       "      <td>2022-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Software Engineer with Security Clearan...</td>\n",
       "      <td>ClearanceJobs</td>\n",
       "      <td>Kirtland, NM</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-soft...</td>\n",
       "      <td>12/25/23</td>\n",
       "      <td>Shiprock</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>LinQuest is seeking a Software Engineer/Develo...</td>\n",
       "      <td>['C++', ' Python', ' MATLAB', ' Visual Basic',...</td>\n",
       "      <td>2021-10-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Sr. Software Engineer – Distributed Graph Stor...   \n",
       "1                    Java Software Engineer (Var 28)   \n",
       "2        Senior Software Engineer (Backend) (Var 65)   \n",
       "3                  Senior Software Engineer (Var 46)   \n",
       "4  Senior Software Engineer with Security Clearan...   \n",
       "\n",
       "                       company              job_location  \\\n",
       "0                  CrowdStrike       Nova Scotia, Canada   \n",
       "1                        Modis                Newark, DE   \n",
       "2              SimplyAnalytics  Toronto, Ontario, Canada   \n",
       "3  Changing Technologies, Inc.              Johnston, IA   \n",
       "4                ClearanceJobs              Kirtland, NM   \n",
       "\n",
       "                                            job_link first_seen  \\\n",
       "0  https://ca.linkedin.com/jobs/view/sr-software-...   12/25/23   \n",
       "1  https://www.linkedin.com/jobs/view/java-softwa...   12/25/23   \n",
       "2  https://ca.linkedin.com/jobs/view/senior-softw...   12/25/23   \n",
       "3  https://www.linkedin.com/jobs/view/senior-soft...   12/25/23   \n",
       "4  https://www.linkedin.com/jobs/view/senior-soft...   12/25/23   \n",
       "\n",
       "       search_city search_country   job level job_type  \\\n",
       "0          Halifax         Canada  Mid senior   Remote   \n",
       "1         Aberdeen  United States  Mid senior   Onsite   \n",
       "2        Etobicoke         Canada  Mid senior   Remote   \n",
       "3  West Des Moines  United States  Mid senior   Onsite   \n",
       "4         Shiprock  United States  Mid senior   Onsite   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  #WeAreCrowdStrike and our mission is to stop b...   \n",
       "1  J2EE Developer - JAVA / Full Stack\\nContract:\\...   \n",
       "2  The Company\\nSimplyAnalytics is a powerful spa...   \n",
       "3  Job Description\\nJob Title - Senior Software E...   \n",
       "4  LinQuest is seeking a Software Engineer/Develo...   \n",
       "\n",
       "                                          job_skills date_posted  \n",
       "0  ['Go', ' Java', ' Python', ' Git', ' Cassandra...  2024-02-14  \n",
       "1  ['J2EE', ' Java', ' Struts', ' Spring', ' Spri...  2024-05-13  \n",
       "2  ['PHP', ' Python', ' Dask', ' Dagster', ' Post...  2024-03-08  \n",
       "3  ['Java', ' React', ' Springboot', ' AWS', ' No...  2022-04-19  \n",
       "4  ['C++', ' Python', ' MATLAB', ' Visual Basic',...  2021-10-09  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing below Python libraries for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Importing the warnings module for handling warning messages\n",
    "import warnings\n",
    "# Ignoring warning messages to prevent interruptions during code execution\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df = pd.read_excel(r\"C:\\Users\\Meghana\\Desktop\\mini project dataset\\linkedin\\final_data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89380"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title           0\n",
      "company             0\n",
      "job_location        0\n",
      "job_link            0\n",
      "first_seen          0\n",
      "search_city         0\n",
      "search_country      0\n",
      "job level           0\n",
      "job_type            0\n",
      "job_summary        39\n",
      "job_skills        126\n",
      "date_posted         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of null values in each column\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "# Print the results\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title         0\n",
      "company           0\n",
      "job_location      0\n",
      "job_link          0\n",
      "first_seen        0\n",
      "search_city       0\n",
      "search_country    0\n",
      "job level         0\n",
      "job_type          0\n",
      "job_summary       0\n",
      "job_skills        0\n",
      "date_posted       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with null values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "# Calculate the number of null values in each column\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "# Print the results\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               job_title             company  \\\n",
      "34799  Patent Attorney / Agent / Electrical / Softwar...  IP Recruiter Group   \n",
      "71573                  Senior Software Engineer (Var 95)       Searchability   \n",
      "79656                    .NET Software Engineer (Var 64)    Vector Solutions   \n",
      "\n",
      "                                   job_location  \\\n",
      "34799                            Alexandria, VA   \n",
      "71573  Nottinghamshire, England, United Kingdom   \n",
      "79656                           Bloomington, IN   \n",
      "\n",
      "                                                job_link first_seen  \\\n",
      "34799  https://www.linkedin.com/jobs/view/patent-atto...   12/25/23   \n",
      "71573  https://uk.linkedin.com/jobs/view/senior-softw...   12/25/23   \n",
      "79656  https://www.linkedin.com/jobs/view/net-softwar...   12/25/23   \n",
      "\n",
      "         search_city  search_country   job level job_type  \\\n",
      "34799  Saint Charles   United States   Associate   Onsite   \n",
      "71573          Derby  United Kingdom  Mid senior   Hybrid   \n",
      "79656   Martinsville   United States  Mid senior   Hybrid   \n",
      "\n",
      "                                             job_summary  \\\n",
      "34799  Please Apply Or Inquire Here\\nwww.iprecruiter....   \n",
      "71573  .Senior Net Developer\\n· Salary up to £50,000\\...   \n",
      "79656  Description:\\nVector Solutions is the leader i...   \n",
      "\n",
      "                                              job_skills date_posted  \n",
      "34799  ['Patent preparation', ' Patent prosecution', ...  2024-01-11  \n",
      "71573  ['C#', ' .NET', ' SQL', ' SQL Server', ' MySQL...  2020-03-15  \n",
      "79656  ['.NET', ' ASP.NET', ' SQL', ' RDBMS', ' HTTP'...  2022-01-13  \n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates based on all columns\n",
    "duplicates_all = df[df.duplicated()]\n",
    "print(duplicates_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(\"Remaining duplicates:\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique companies: 3369\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique companies in the 'company' column\n",
    "unique_companies_count = df['company'].nunique()\n",
    "\n",
    "# Display the count\n",
    "print(f\"Number of unique companies: {unique_companies_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique companies from the 'company' column\n",
    "unique_companies = df['company'].unique()\n",
    "\n",
    "# Convert the array to a list (optional)\n",
    "unique_companies_list = unique_companies.tolist()\n",
    "\n",
    "# Display the companies\n",
    "#print(\"Unique companies:\")\n",
    "#for company in unique_companies_list:\n",
    "#    print(company)\n",
    "\n",
    "# Save the list of unique companies to a new file (optional)\n",
    "pd.DataFrame(unique_companies_list, columns=['company']).to_csv('unique_companies.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Job Levels: ['Mid senior' 'Associate']\n",
      "Unique Job Types: ['Remote' 'Onsite' 'Hybrid']\n"
     ]
    }
   ],
   "source": [
    "# Get unique job levels\n",
    "unique_job_levels = df['job level'].unique()\n",
    "\n",
    "# Get unique job types\n",
    "unique_job_types = df['job_type'].unique()\n",
    "\n",
    "print(\"Unique Job Levels:\", unique_job_levels)\n",
    "print(\"Unique Job Types:\", unique_job_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Level Counts:\n",
      "job level\n",
      "Mid senior    77102\n",
      "Associate     12149\n",
      "Name: count, dtype: int64\n",
      "Job Type Counts:\n",
      "job_type\n",
      "Onsite    41040\n",
      "Hybrid    26174\n",
      "Remote    22037\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each job level\n",
    "job_level_counts = df['job level'].value_counts()\n",
    "\n",
    "# Count occurrences of each job type\n",
    "job_type_counts = df['job_type'].value_counts()\n",
    "\n",
    "print(\"Job Level Counts:\")\n",
    "print(job_level_counts)\n",
    "print(\"Job Type Counts:\")\n",
    "print(job_type_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nova Scotia, Canada' 'Newark, DE' 'Toronto, Ontario, Canada' ...\n",
      " 'Rugeley, England, United Kingdom' 'Marina del Rey, CA'\n",
      " 'Chippendale, New South Wales, Australia']\n"
     ]
    }
   ],
   "source": [
    "# Find unique countries\n",
    "unique_countries = df['job_location'].unique()\n",
    "\n",
    "# Print the unique countries\n",
    "print(unique_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       company          job_city job_country\n",
      "0                  CrowdStrike       Nova Scotia      Canada\n",
      "1                        Modis            Newark          DE\n",
      "2              SimplyAnalytics  Toronto, Ontario      Canada\n",
      "3  Changing Technologies, Inc.          Johnston          IA\n",
      "4                ClearanceJobs          Kirtland          NM\n"
     ]
    }
   ],
   "source": [
    "# Split the job_location column by commas\n",
    "df[['job_city', 'job_country']] = df['job_location'].str.rsplit(',', n=1, expand=True)\n",
    "\n",
    "# Clean up any extra spaces\n",
    "df['job_city'] = df['job_city'].str.strip()\n",
    "df['job_country'] = df['job_country'].str.strip()\n",
    "\n",
    "# Display the first few rows with city and country columns\n",
    "print(df[['company', 'job_city', 'job_country']].head())\n",
    "df.drop(columns=['first_seen'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique countries:\n",
      "['Canada' 'DE' 'IA' 'NM' 'United States' 'GA' 'NY' 'RI' 'CA' 'WA' None\n",
      " 'AL' 'CO' 'United Kingdom' 'CT' 'TX' 'MN' 'Australia' 'WI' 'MI' 'IL' 'FL'\n",
      " 'NH' 'NV' 'UT' 'KS' 'OK' 'PA' 'MA' 'MT' 'SC' 'VA' 'NJ' 'ME' 'IN' 'WV'\n",
      " 'OH' 'MO' 'AZ' 'MD' 'NC' 'AR' 'OR' 'TN' 'DC' 'LA' 'KY' 'ND' 'NE' 'HI'\n",
      " 'Ohio Metropolitan Area' 'Texas Metropolitan Area'\n",
      " 'New York Metropolitan Area' 'ID' 'VT' 'SD' 'MS' 'Mexico' 'Alabama Area'\n",
      " 'WY' 'Oregon Metropolitan Area' 'North Carolina Metropolitan Area' 'AK'\n",
      " 'South Carolina Metropolitan Area' 'Maine Metropolitan Area'\n",
      " 'South Carolina Area' 'Indiana Metropolitan Area'\n",
      " 'Louisiana Metropolitan Area' 'MI Area']\n",
      "\n",
      "Number of null values in 'country' column: 4223\n"
     ]
    }
   ],
   "source": [
    "# Get unique countries\n",
    "unique_countries = df['job_country'].unique()\n",
    "\n",
    "# Count null values in the 'country' column\n",
    "null_values_count = df['job_country'].isnull().sum()\n",
    "\n",
    "# Print the results\n",
    "print(\"Unique countries:\")\n",
    "print(unique_countries)\n",
    "\n",
    "print(\"\\nNumber of null values in 'country' column:\", null_values_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of null values in 'country' column: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89251"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the city value to country where country is null\n",
    "df['job_country'] = df['job_country'].fillna(df['job_city'])\n",
    "null_values_count = df['job_country'].isnull().sum()\n",
    "print(\"\\nNumber of null values in 'country' column:\", null_values_count)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Job Titles:\n",
      "['Sr. Software Engineer – Distributed Graph Storage Systems (Remote, CAN) (Var 15)'\n",
      " 'Java Software Engineer (Var 28)'\n",
      " 'Senior Software Engineer (Backend) (Var 65)' ...\n",
      " 'Real Time Software Engineer 3'\n",
      " '6J7BI4-Software Engineer 4 - 6D6-Real Time Software Engineer'\n",
      " '6J7BI3-Software Engineer 3 - 6D6-Real Time Software Engineer with Security Clearance']\n",
      "\n",
      "Total unique job titles: 52065\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "\n",
    "# Get unique job titles and print them\n",
    "unique_designation = df['job_title'].unique()\n",
    "print(\"Unique Job Titles:\")\n",
    "print(unique_designation)\n",
    "\n",
    "# Count the number of unique job titles\n",
    "unique_designation_count = len(unique_designation)\n",
    "print(f\"\\nTotal unique job titles: {unique_designation_count}\")\n",
    "\n",
    "# Drop the 'job_location' column\n",
    "#df.drop('job_location', axis=1, inplace=True)\n",
    "#print(\"\\n'job_location' column dropped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ['Go', ' Java', ' Python', ' Git', ' Cassandra...\n",
      "1    ['J2EE', ' Java', ' Struts', ' Spring', ' Spri...\n",
      "2    ['PHP', ' Python', ' Dask', ' Dagster', ' Post...\n",
      "Name: job_skills, dtype: object\n",
      "Number of null values in job_skills: 0\n"
     ]
    }
   ],
   "source": [
    "print(df['job_skills'].iloc[0:3])\n",
    "# Check for null values in the 'job_skills' column\n",
    "null_values = df['job_skills'].isnull().sum()\n",
    "\n",
    "# Print the number of null values\n",
    "print(f'Number of null values in job_skills: {null_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common skills in the dataset:\n",
      "' Python': 27986\n",
      "' AWS': 22942\n",
      "' SQL': 20698\n",
      "' JavaScript': 20240\n",
      "' Java': 18711\n",
      "' Agile': 16457\n",
      "' Kubernetes': 14824\n",
      "' Git': 14481\n",
      "' Docker': 14207\n",
      "' React': 12922\n",
      "\n",
      "Processed Data:\n",
      "                                           job_title  \\\n",
      "0  Sr. Software Engineer – Distributed Graph Stor...   \n",
      "1                    Java Software Engineer (Var 28)   \n",
      "2        Senior Software Engineer (Backend) (Var 65)   \n",
      "3                  Senior Software Engineer (Var 46)   \n",
      "4  Senior Software Engineer with Security Clearan...   \n",
      "\n",
      "                                          job_skills  \\\n",
      "0  ['Go', ' Java', ' Python', ' Git', ' Cassandra...   \n",
      "1  ['J2EE', ' Java', ' Struts', ' Spring', ' Spri...   \n",
      "2  ['PHP', ' Python', ' Dask', ' Dagster', ' Post...   \n",
      "3  ['Java', ' React', ' Springboot', ' AWS', ' No...   \n",
      "4  ['C++', ' Python', ' MATLAB', ' Visual Basic',...   \n",
      "\n",
      "                                         skills_list  \n",
      "0  [['Go', ' Java', ' Python', ' Git', ' Cassandr...  \n",
      "1  [['J2EE', ' Java', ' Struts', ' Spring', ' Spr...  \n",
      "2  [['PHP', ' Python', ' Dask', ' Dagster', ' Pos...  \n",
      "3  [['Java', ' React', ' Springboot', ' AWS', ' N...  \n",
      "4  [['C++', ' Python', ' MATLAB', ' Visual Basic'...  \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Split 'job_skills' into individual skills and clean up the list\n",
    "if 'job_skills' in df.columns:\n",
    "    df['skills_list'] = df['job_skills'].str.split(r'[,\\n;]+').apply(lambda x: [skill.strip() for skill in x if skill.strip()])\n",
    "\n",
    "    # Count the frequency of each skill\n",
    "    all_skills = [skill for sublist in df['skills_list'].dropna() for skill in sublist]\n",
    "    skill_counts = Counter(all_skills)\n",
    "    \n",
    "    # Display the most common skills\n",
    "    print(\"\\nMost common skills in the dataset:\")\n",
    "    for skill, count in skill_counts.most_common(10):\n",
    "        print(f\"{skill}: {count}\")\n",
    "\n",
    "    # Display processed data with extracted skills\n",
    "    print(\"\\nProcessed Data:\")\n",
    "    print(df[['job_title', 'job_skills', 'skills_list']].head())\n",
    "else:\n",
    "    print(\"Warning: 'job_skills' column not found, skipping skill extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common skills in the dataset:\n",
      "' Python': 27986\n",
      "' AWS': 22942\n",
      "' SQL': 20698\n",
      "' JavaScript': 20240\n",
      "' Java': 18711\n",
      "' Agile': 16457\n",
      "' Kubernetes': 14824\n",
      "' Git': 14481\n",
      "' Docker': 14207\n",
      "' React': 12922\n",
      "\n",
      "Total most common skills (top 10): 10\n",
      "\n",
      "First 6 unique skills and their counts:\n",
      "['Go': 870\n",
      "' Java': 18711\n",
      "' Python': 27986\n",
      "' Git': 14481\n",
      "' Cassandra': 1661\n",
      "' Kafka': 3778\n",
      "\n",
      "Total unique skills: 35881\n",
      "\n",
      "Processed Data:\n",
      "                                           job_title  \\\n",
      "0  Sr. Software Engineer – Distributed Graph Stor...   \n",
      "1                    Java Software Engineer (Var 28)   \n",
      "2        Senior Software Engineer (Backend) (Var 65)   \n",
      "3                  Senior Software Engineer (Var 46)   \n",
      "4  Senior Software Engineer with Security Clearan...   \n",
      "\n",
      "                       company  \\\n",
      "0                  CrowdStrike   \n",
      "1                        Modis   \n",
      "2              SimplyAnalytics   \n",
      "3  Changing Technologies, Inc.   \n",
      "4                ClearanceJobs   \n",
      "\n",
      "                                          job_skills  \\\n",
      "0  ['Go', ' Java', ' Python', ' Git', ' Cassandra...   \n",
      "1  ['J2EE', ' Java', ' Struts', ' Spring', ' Spri...   \n",
      "2  ['PHP', ' Python', ' Dask', ' Dagster', ' Post...   \n",
      "3  ['Java', ' React', ' Springboot', ' AWS', ' No...   \n",
      "4  ['C++', ' Python', ' MATLAB', ' Visual Basic',...   \n",
      "\n",
      "                                         skills_list  \n",
      "0  [['Go', ' Java', ' Python', ' Git', ' Cassandr...  \n",
      "1  [['J2EE', ' Java', ' Struts', ' Spring', ' Spr...  \n",
      "2  [['PHP', ' Python', ' Dask', ' Dagster', ' Pos...  \n",
      "3  [['Java', ' React', ' Springboot', ' AWS', ' N...  \n",
      "4  [['C++', ' Python', ' MATLAB', ' Visual Basic'...  \n",
      "\n",
      "CSV file created: processed_job_skills.csv\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame (replace with your actual DataFrame)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Split 'job_skills' into individual skills and clean up the list\n",
    "if 'job_skills' in df.columns:\n",
    "    df['skills_list'] = df['job_skills'].str.split(r'[,\\n;]+').apply(lambda x: [skill.strip() for skill in x if skill.strip()])\n",
    "\n",
    "    # Count the frequency of each skill\n",
    "    all_skills = [skill for sublist in df['skills_list'].dropna() for skill in sublist]\n",
    "    skill_counts = Counter(all_skills)\n",
    "    \n",
    "    # Display the most common skills (top 10)\n",
    "    print(\"\\nMost common skills in the dataset:\")\n",
    "    most_common_skills = skill_counts.most_common(10)\n",
    "    for skill, count in most_common_skills:\n",
    "        print(f\"{skill}: {count}\")\n",
    "    \n",
    "    # Total most common skills (top 10)\n",
    "    total_most_common_skills = len(most_common_skills)\n",
    "    print(f\"\\nTotal most common skills (top 10): {total_most_common_skills}\")\n",
    "\n",
    "    # Display the first 6 unique skills and their counts\n",
    "    print(\"\\nFirst 6 unique skills and their counts:\")\n",
    "    for skill, count in list(skill_counts.items())[:6]:  # Limiting to first 6 skills\n",
    "        print(f\"{skill}: {count}\")\n",
    "    \n",
    "    # Count the number of unique skills\n",
    "    unique_skills_count = len(skill_counts)\n",
    "    print(f\"\\nTotal unique skills: {unique_skills_count}\")\n",
    "\n",
    "    # Display processed data with extracted skills\n",
    "    print(\"\\nProcessed Data:\")\n",
    "    print(df[['job_title', 'company', 'job_skills', 'skills_list']].head())\n",
    "\n",
    "    # Create a CSV file with the job title, company, job skills, and the processed skills list\n",
    "    output_file = 'processed_job_skills.csv'\n",
    "    df[['job_title', 'company', 'job_skills', 'skills_list']].to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"\\nCSV file created: {output_file}\")\n",
    "else:\n",
    "    print(\"Warning: 'job_skills' column not found, skipping skill extraction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title                 object\n",
       "company                   object\n",
       "job_location              object\n",
       "job_link                  object\n",
       "search_city               object\n",
       "search_country            object\n",
       "job level                 object\n",
       "job_type                  object\n",
       "job_summary               object\n",
       "job_skills                object\n",
       "date_posted       datetime64[ns]\n",
       "job_city                  object\n",
       "job_country               object\n",
       "skills_list               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                 89251\n",
       "unique                 3369\n",
       "top       Jobs for Humanity\n",
       "freq                   6509\n",
       "Name: company, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of the \"Total_applicants\" column\n",
    "df[\"company\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          89251\n",
       "unique             2\n",
       "top       Mid senior\n",
       "freq           77102\n",
       "Name: job level, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of the \"Total_applicants\" column\n",
    "df[\"job level\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      89251\n",
       "unique         3\n",
       "top       Onsite\n",
       "freq       41040\n",
       "Name: job_type, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of the \"Total_applicants\" column\n",
    "df[\"job_type\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count              89251\n",
       "unique               133\n",
       "top       United Kingdom\n",
       "freq               10428\n",
       "Name: job_country, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of the \"Total_applicants\" column\n",
    "df[\"job_country\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
